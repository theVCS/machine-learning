#################################   MODEL SELECTION  #####################################
model_params = {
    'svm': {
        'model': svm.SVC(gamma='auto'),
        'params': {
            'C': [1, 10, 20],
            'kernel': ['rbf', 'linear']
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params': {
            'n_estimators': [1, 5, 10]
        }
    },
    'logistic_regression': {
        'model': LogisticRegression(solver='liblinear', multi_class='auto'),
        'params': {
            'C': [1, 5, 10]
        }
    },
    'decision_tree': {
        'model': DecisionTreeClassifier(random_state=23, class_weight='balanced'),
        'params': {
            'max_depth':[3, 5, 8, 10, 15, 50],
            'min_samples_split':[5, 10, 100, 500, 1000],
            'max_leaf_nodes': list(range(30, 50))
        }
    },
    'GaussianNB': {
        'model': GaussianNB(),
        'params': {
            'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]
        }
    },
    'MultinomialNB': {
        'model': MultinomialNB(),
        'params': {
            'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],
        }
    },
    'BernoulliNB': {
        'model': BernoulliNB(),
        'params': {
            'alpha':np.linspace(0.1,1,10)
        }
    },
}

scores = []

for model_name, mp in model_params.items():
    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)
    clf.fit(digits.data, digits.target)
    scores.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    
df = pd.DataFrame(scores,columns=['model','best_score','best_params'])
df
############################################################################################





<---------------------------------  HYPERPARAMETER TUNING  ------------------------------>


#####################################  Random Forest  ######################################
model_params = {
    'random_forest': {
        'model': RandomForestClassifier(),
        'params': {
                'n_estimators': randint(10,100),
                "max_features": randint(1,64),
                'max_depth': [randint(5,50), None],
                "min_samples_split": randint(2,11),
                "min_samples_leaf": randint(1,11),
                "criterion":['gini','entropy'],
                "bootstrap": [True, False],
        }
    },
}

score = []

for model_name, mp in model_params.items():
    clf =  RandomizedSearchCV(mp['model'], mp['params'], n_iter=200, cv=3,scoring='accuracy')
    clf.fit(X, y)
    score.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    
df = pd.DataFrame(score,columns=['model','best_score','best_params'])
df
################################### END #################################################






#############################################  SVM  ############################################
model_params = {
    'svm': {
        'model': svm.SVC(),
        'params': {
            'C': [0.1,1, 10, 100], 
            'gamma': [1,0.1,0.01,0.001],
            'kernel': ['rbf', 'poly', 'sigmoid'],
        }
    },
}

score = []

for model_name, mp in model_params.items():
    clf =  RandomizedSearchCV(mp['model'], mp['params'], n_iter=50, cv=3,scoring='accuracy')
    clf.fit(digits.data, digits.target)
    score.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    
df = pd.DataFrame(score,columns=['model','best_score','best_params'])
df
################################### END #################################################







###################################  LOGISTIC REGRESSION ################################
model_params = {
    'logistic_regression': {
        'model': LogisticRegression(),
        'params': {
            'penalty' : ['l1', 'l2', 'elasticnet', 'none'],
            'C' : np.logspace(-4, 4, 20),
            'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],
            'max_iter' : [100, 1000,2500, 5000]

        }
    },
}

score = []

for model_name, mp in model_params.items():
    clf =  RandomizedSearchCV(mp['model'], mp['params'], n_iter=50, cv=3,scoring='accuracy')
    clf.fit(digits.data, digits.target)
    score.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    
df = pd.DataFrame(score,columns=['model','best_score','best_params'])
df
################################### END #################################################






###################################  DECISION TREE ################################
model_params = {
    'decision_tree': {
        'model': DecisionTreeClassifier(),
        'params': {
            "max_depth": [2, 3, 4, 5, 6, 7, 8 , 9, None],
            "max_features": [2, 3, 4, 5, 6, 7, 8 , 9],
            "min_samples_leaf": [2, 3, 4, 5, 6, 7, 8 , 9, None],
            "criterion": ["gini", "entropy"],
            "splitter": ["best", "random"]
        }
    },
}

score = []

for model_name, mp in model_params.items():
    clf =  RandomizedSearchCV(mp['model'], mp['params'], n_iter=50, cv=3,scoring='accuracy')
    clf.fit(digits.data, digits.target)
    score.append({
        'model': model_name,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    
df = pd.DataFrame(score,columns=['model','best_score','best_params'])
df
################################### END #################################################











for i, j in df["best_params"][0].items():
    print("{}='{}',".format(i,j), end=" ")